# Fine-tuning 触ってみた

## データ

英語の文章読解問題

SAT （日本のセンター試験に近いテスト）でよく使われる問題形式で、与えられた文章について４〜５択の質問に答える

説明つき例題を探すのが少し難しかったので、取り合えす

- 学習：１０問
- 評価：５問

で実験してみた

答えを JSON 形式で要求（fine-tuning と関数呼び出しの組み合わせはまだ不可能）

## 結果

評価問題をそれぞれ 10 回モデルに投げてその結果で評価

| モデル     | GPT-3 | GPT-3 fine-tuned | GPT-3+function | GPT-4 |
| ---------- | ----- | ---------------- | -------------- | ----- |
| 正解       | 12    | 15               | 14             | 26    |
| 不正解     | 34    | 34               | 36             | 16    |
| 不正な形式 | 6     | 1                | 0              | 4     |
| API エラー | 0     | 0                | 0              | 7     |

## 感想

- 確かに fine-tuning した方が形式を守ってくれるけど、それだけなら関数の方がいい
- fine-tuning の正解率が高いのは誤差のうち？
- やはり GPT-4 が強い
- データを増やして・もっと fine-tuning に適したデータでも実験してみたい
