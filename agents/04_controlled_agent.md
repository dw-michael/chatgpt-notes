[« ツール工夫](./03_langchain2.md) | | [制御エージェント v2 »](./05_controlled_agent2.md)

# 概要

LLM の高い自由度で発生する問題が多くて、実運用は限られたタスクで使うことが基本なので、がっつり制御されたエージェントを作ったら良くなるのかも？

# 手順

1. LLM にタスクを教えて、プランを立ててもらう
2. LLM にプラン、進行状態、ツールのリストを提供して、次に使うツールを選んでもらう
3. LLM にプラン、進行状態、選ばれたツールとその説明を提供して、ツールを使ってもらう
4. 答えが出るまで 2、3 を繰り返す

## 工夫点

- チャット形式でやると、どうせ毎回全てのチャット履歴を送るので、今回はチャット履歴をほぼ持たずに zero-shot あるいは few-shot で全てのステップを行う。データは変数に保存され、進行状態は常に更新されるので zero-shot でもタスクはすすむ
  - トークン数削減できるかも？
- 常に出力を評価してもらっている。ツールを使った後、そのツールの結果を LLM 自身に評価してもらい成功か失敗か判断する。失敗が発生したら反省してプランを見直してもらう

## コード

https://github.o-in.dwango.co.jp/michael/controlled-llm-agent

## 感想

- デバッグしやすい
  - プロンプト工夫はデバッグに入るかどうかはさておき、問題の箇所が特定しやすくなったし直しやすくなった
  - ライブラリのエージェントだと、最初のプロンプトとツール説明だけを調整できるけどそのあとは祈るしかなかった
- エラー落ちはほぼゼロ（自分でエラー処理書いたからそれはそう）
- 出力の工夫が大事
  - 入力は transformer で処理されるから順番はそこまで大事じゃないけど、出力は順番に生成されるので、まずは「考えさせる」ことが大事だとわかった
  - 例えばツール選択前は「Reasoning:」を書かせる。書いたことは保存されなくて、単にデバッグ用＋ツール選択の精度を上げる用
- 最初のプランがダメだったときは基本的に全部ダメ
- 終わりどきが見つからない
  - タスクが終わっても「終わる」を選択せずに、変に途中のステップからまたやっていく
- 一回脱線すると戻らない
- 使用率がすごい
  - メッセージ履歴を持たないとはいえ、普通のエージェントだと一回のやり取りが、ツール選択＋ツール使用＋フィードバックで３倍になっちゃう
  - あと課金したからレートリミットが解除され単純にもっと実行しているかも
- 結論：やっぱり GPT4 使いたい

# TODO

- プランを固定にする？
  - プラン関係の問題は無くなるが、LLM のありがたみがかなり減るのでは
- プランをユーザー指定ができるようにする？
  - 自然言語で書けるぶん楽ではあるが、やはり LLM のありがたみが
